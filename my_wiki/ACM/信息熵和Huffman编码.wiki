= 信息熵和Huffman编码 =


* [[http://mindhacks.cn/2011/07/10/the-importance-of-knowing-why-part3/|知其所以然（三）：为什么算法这么难？]]
* [[http://blog.csdn.net/xiyanxiyan10/article/details/17580599|huffman的证明]]

* [[https://www.zhihu.com/question/22178202/answer/205519701|信息熵为什么使用log函数]]

     补充一下为什么用log函数。这个涉及两个问题：1.对进制的理解。2.可计算性的理解。对进制的理解。如果是10进制，每一位可以表达10种可能。2位就表达100种。同理，2进制。再说概率，如果一件事情的概率是1/1000，那么隐含的说法就是有1000种情况。为了给1000个情况编码需要几位？用10进制就是3位。2进制就是10位。在计算机中，都是用2进制，所以就用2为底。可计算性的理解设概率p, 那么1/p就是可看成不确定性。如果两种情况的概率分别是 P(A)=p1,P(B)=p2那么P(AB)=p1*p2由于p1,p2都是小于1的数，如果求多个情况一起发生的概率，而且每个概率都很小。p1*p2*p3...= 0.001*0.002*0.0003..........那么，这个数字很快就小到超出计算机的表达范围。同时，对于不确定性，1/p1*1/p2.....很快就大到无法表示。所以，转化成log计算，就解决了这个问题。


* [[https://acm.sjtu.edu.cn/w/images/6/65/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E5%8E%8B%E7%BC%A9%E4%B8%8E%E4%BF%A1%E6%81%AF%E7%86%B5.pdf|数据编码压缩和信息熵]]
* [[http://blog.csdn.net/u013354805/article/details/50112353|数字视频编码概述(熵编码/Huffman编码)]]
* [[https://www.zhihu.com/question/22539777|从信息熵的角度来看，数据压缩是一种怎样的过程？]]


* 最短平均编码长度
* 压缩比: 越小越好
* 编码效率 : 等于1就达到了香农所说的最短平均编码长度， 大于1就是有损压缩
