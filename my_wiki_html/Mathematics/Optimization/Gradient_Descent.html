<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Gradient Descent</title>
    <link rel="Stylesheet" type="text/css" href="../../assets/css/style.css" />
    <link rel="stylesheet" type="text/css" href="../../assets/google-code-prettify/prettify.css" >
    <!--<link rel="stylesheet" type="text/css" href="../../assets/css/amazeui.min.css" > -->
    <link rel="stylesheet" type="text/css" href="../../assets/css/autoc.css" >
    <!-- add more style sheets and javascripts -->
</head>
<body>
<!--<body onload="prettyPrint()">-->
<nav>
    <a href="../../index.html">Index</a>
    <a href="https://github.com/antonaaa/">Github</a>
    <a href="../../about.html">About</a>
    <a href="../../sitemap.html">SiteMap</a>
</nav>

<div class="content">


<div id="Gradient Descent"><h1 id="Gradient Descent">Gradient Descent</h1></div>
<blockquote>
前面所说的一维搜索是在确定了下降方向之后，求合适步长\(\alpha_k\)的算法。而梯度下降法是求下降方向的算法。
</blockquote>
	
	
<div id="Gradient Descent-梯度下降法的定义"><h2 id="梯度下降法的定义">梯度下降法的定义</h2></div>
<p>
由方向导数的定义\(\frac{\partial f(x)}{\partial p} = \nabla^T f(x) p = | \nabla^T f(x)| |p| \cos \theta = | \nabla^T f(x)| \cos \theta\)(其中\(p\)是单位方向向量)，可知：
</p>

<ul>
<li>
\(p\)是梯度方向\(\nabla f(x)\)的方向单位向量时，\(\cos \theta = 1\)，方向导数最大（当前位置上升最快的方向）；

<li>
当\(p\)是负梯度方向\(-\nabla f(x)\)的方向单位向量时，\(\cos \theta = -1\)，方向导数最小，（当前位置下降最快的方向）；

</ul>

<hr />
<p>
由上面这个事实就能得到梯度下降法是如何工作的了
</p>

<ul>
<li>
当迭代了k次之后，来到了迭代点\(x_k\)

<li>
现在要进行第\(k + 1\)次迭代，那么应该负梯度方向\(-\nabla f(x_k)\)进行一维搜索，确定合适的步长

<li>
所以坐标点的迭代公式为\(x_{k+1} = x_k - \alpha_k \nabla f(x_k)\)

</ul>


<div id="Gradient Descent-算法流程"><h2 id="算法流程">算法流程</h2></div>
<ol>
<li>
选定初始点\(x_k\)

<li>
计算初始点的函数值和梯度，\(f_k := f(x_k), g_k := \nabla f(x_k)\)

<li>
计算下一个迭代点\(x_{k+1} := x_k - \alpha_k g_k\)，此时应该调用一维搜索确定合适的步长。

<li>
计算\(f_{x+1} := f(x_{k+1}), g_{k+1} := \nabla f(x_{k+1})\)，判断是否满足终止准则 （终止准则的分析应该另外写成一章，此处附上链接）

<li>
如果满足，则输出\(x_{k+1}\)和\(f_{k+1}\)。

<li>
如果不满足，则令\(x_k := x_{k+1}, f_k := f_{k+1}, g_k := g_{k+1}\)，返回第2步继续迭代。

</ol>


<div id="Gradient Descent-正定二次函数的最优步长"><h2 id="正定二次函数的最优步长">正定二次函数的最优步长</h2></div>
<blockquote>
正定二次函数\(f(x) = \frac{1}{2} x^TQx + bx + c\)在负梯度方向上的最优步长是有公式可以求的。
</blockquote>
	
	
<p>
如果每次沿着负梯度方向都走最优步长，那么相邻两次迭代点的梯度是正交的。
</p>

<p>
<a href="..&#47;..&#47;..&#47;my_wiki&#47;Mathematics&#47;Optimization&#47;resources&#47;梯度下降1.png"><img src="../../../my_wiki/Mathematics/Optimization/resources/梯度下降1.png" alt="函数图像" /></a>
</p>

<ul>
<li>
\(\nabla^T f(x_{k+1}) \nabla f(x_k) = 0\)

</ul>
<hr />

<ul>
<li>
\(f(x) = \frac{1}{2} x^TQx + bx + c\)

<li>
\(\nabla^T f(x) = Qx + b\)

<li>
\(Q^T = Q\)

<li>
\(x_{k+1} = x_k - \alpha_k \nabla f(x_k)\)

</ul>
<p>
由上面的已知条件可以推出
</p>
<ul>
<li>
\(\Rightarrow \;\)  \(\nabla^T f(x_{k+1}) \nabla f(x_k) = (Q(x_k - \alpha_k \nabla f(x_k) + b))^T \nabla f(x_k) = 0\)。

<li>
\(\Rightarrow \;\) \((Q x_k  + b- \alpha_k Q \nabla f(x_k))^T \nabla f(x_k) = 0\)

<li>
\(\Rightarrow \;\) \((\nabla f(x_k) - \alpha_k \nabla f(x_k)Q)^T \nabla f(x_k) = 0\)

<li>
\(\Rightarrow \;\) \((\nabla^T f(x_k) - \alpha_k \nabla^T f(x_k)Q) \nabla f(x_k) = 0\)

<li>
\(\Rightarrow \;\) \(\nabla^T f(x_k) \nabla f(x_k) - \alpha_k \nabla^T f(x_k)Q \nabla f(x_k) = 0\)

<li>
\(\Rightarrow \;\) \(\nabla^T f(x_k) \nabla f(x_k) = \alpha_k \nabla^T f(x_k)Q \nabla f(x_k)\)

<li>
\(\Rightarrow \;\) \(\alpha_k = \frac{\nabla^T f(x_k) \nabla f(x_k)}{\nabla^T f(x_k) Q \nabla f(x_k)}\)

</ul>

<p>
所以正定二次函数\(f(x) = \frac{1}{2} x^TQx + bx + c\)在负梯度方向上的最优步长公式是：\(\alpha_k = \frac{\nabla^T f(x_k) \nabla f(x_k)}{\nabla^T f(x_k) Q \nabla f(x_k)}\)
</p>

<p>
所以迭代公式是：\(x_{k+1} = x_k - \frac{\nabla^T f(x_k) \nabla f(x_k)}{\nabla^T f(x_k) Q \nabla f(x_k)} \nabla f(x_k)\)
</p>

<div id="Gradient Descent-梯度下降法的锯齿现象"><h2 id="梯度下降法的锯齿现象">梯度下降法的锯齿现象</h2></div>
<p>
	如果每次沿负梯度方向都是走最优步长，那么相邻两次迭代的点的梯度是垂直的，称这种现象为锯齿现象
<a href="..&#47;..&#47;..&#47;my_wiki&#47;Mathematics&#47;Optimization&#47;resources&#47;梯度下降2.png"><img src="../../../my_wiki/Mathematics/Optimization/resources/梯度下降2.png" alt="函数图像" /></a>
</p>

<p>
直观上上：
</p>

<ul>
<li>
远离极值点时，每次迭代都有可能使函数值有较多的下降

<li>
靠近极值点时，由于锯齿现象，使得每次迭代行进的距离缩短，因而收敛速度不快，这正是梯度下降法的缺点所在。

</ul>
	
<div id="Gradient Descent-梯度下降法的收敛速度"><h2 id="梯度下降法的收敛速度">梯度下降法的收敛速度</h2></div>

<p>
梯度下降法对于正定二次函数在任意的初始点都是收敛的，而且恰好是线性收敛
</p>

</div>

<hr class="comment">
<section class="comment">
<div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'lotaboutvimwiki'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>

   
</section>

<footer>
    声明，本文采用<a href="http://creativecommons.org/licenses/by-nc-sa/3.0/">CC BY-NC-SA 3.0</a>授权。
</footer>


<style>
.sdsm-menu li:hover {
    color: #146;
}

.sdsm-menu li.active.first {
    font-weight: bold;
    color: #a19d38;
}

.sdsm-menu li.active {
    color: #a19d38;
}
</style>

    <script src="../../assets/js/jquery-1.7.1.min.js"></script>
    <script src="../../assets/js/autoc.min.js"></script>
    <script type="text/javascript">
        $(document).ready(function(){
        $('pre').addClass('prettyprint linenums') 
        prettyPrint()
		new AutocJS({
			article: '.content',
			title: 'Tabel of Contents',
			selector: 'h2, h3, h4, h5, h6'
		});
});



    </script>
    <script src="../../assets/google-code-prettify/prettify.js"></script>

    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
